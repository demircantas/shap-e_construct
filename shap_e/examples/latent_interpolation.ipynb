{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eed3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1570073",
   "metadata": {},
   "source": [
    "# load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d922637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xm is for rendering latents\n",
    "xm = load_model('transmitter', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/content/drive/MyDrive/thesis/batch/\n",
    "\n",
    "## get paths of all latents in the folder.\n",
    "latent_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "## load all latents\n",
    "latents = [torch.load(latent_path).to(device) for latent_path in latent_paths]\n",
    "\n",
    "## convert latents to tensor of shape [2, 1048576]\n",
    "latents = torch.stack(latents).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "408b601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load latents from file\n",
    "if 0:\n",
    "    latents_cube = torch.load('../../../content/batch_output/chair_baby_1.npy')\n",
    "    latents_cube_tall = torch.load('../../../content/batch_output/chair_baby_2.npy')\n",
    "    # latents_cube_tall = torch.load('../../latents/cube_tall_latents.pt')\n",
    "    # print minimum and maximum values of latents\n",
    "    print(f'latents_cube min: {latents_cube.min()}')\n",
    "    print(f'latents_cube max: {latents_cube.max()}')\n",
    "    print(f'latents_cube_tall min: {latents_cube_tall.min()}')\n",
    "    print(f'latents_cube_tall max: {latents_cube_tall.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd4b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for plotting a histogram of latents\n",
    "def plot_hist(latents):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(latents.flatten().cpu().numpy(), bins=500)\n",
    "    plt.show()\n",
    "\n",
    "# function for interpolating among two latent vectors\n",
    "def interpolate_latents(lat_A, lat_B, intp_steps):\n",
    "    latents = []\n",
    "    for i in range(intp_steps):\n",
    "        latents.append(lat_A + (lat_B - lat_A) * i / intp_steps)\n",
    "    return torch.stack(latents)\n",
    "\n",
    "# function for extrapolating from a latent vector\n",
    "def extrapolate_latents(lat_A, lat_B, extp_steps):\n",
    "    latents = []\n",
    "    for i in range(extp_steps):\n",
    "        latents.append(lat_B + (lat_B - lat_A) * i / extp_steps)\n",
    "    return torch.stack(latents)\n",
    "\n",
    "# function for extracting transformation from two latent vectors\n",
    "def extract_transformation(lat_A, lat_B):\n",
    "    return lat_B - lat_A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_transform = extract_transformation(latents_cube[0], latents_cube_tall[0])\n",
    "# print the indices of five largest values in the latent_transform vector\n",
    "print(torch.topk(latent_transform, 5))\n",
    "\n",
    "plot_hist(latents_cube)\n",
    "plot_hist(latent_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41dfed91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1048576])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents_cube[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d8a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate between two latents\n",
    "intp_latents = interpolate_latents(latents_cube, latents_cube_tall, 10)\n",
    "extp_latents = extrapolate_latents(latents_cube_tall, latents_cube, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abf62fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1048576])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(intp_latents))\n",
    "intp_latents[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d2a887",
   "metadata": {},
   "source": [
    "# render latents\n",
    "\n",
    "## *render_transformation* function below took:\n",
    "\n",
    "| size | samples | time |\n",
    "| --- | --- | --- |\n",
    "| 32 | 5 | 15m21.0s |\n",
    "| 32 | 10 | 38m25.5s |\n",
    "| 32 | 10 | 54m50.5s |\n",
    "|___|___|___|\n",
    "| 64 | 20 | 14m5.7s |\n",
    "| 64 | 20 | 19m40.4s |\n",
    "| 64 | 20 | 31m.52.9s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f14a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf' for mesh rendering\n",
    "# size = 64 # this is the size of the renders; higher values take longer to render.\n",
    "size = 32 # this is the size of the renders; higher values take longer to render. 16 causes an assertion error.\n",
    "cameras = create_pan_cameras(size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f6f5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for rendering interpolated or extrapolated latents\n",
    "def render_latents(latents):\n",
    "    for i, latent in enumerate(latents):\n",
    "        images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    return images\n",
    "    # images = []\n",
    "    # for latent in latents:\n",
    "    #     images.append(decode_latent_images(xm, latent, cameras, rendering_mode=render_mode))\n",
    "    #     # images[0].save('../../../content/{}_{}.gif'.format(name, i), save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "    # return images\n",
    "\n",
    "# function for rendering the interpolation between two latents as a single gif\n",
    "def render_transformation(latents, name):\n",
    "    # render the first frame from the first latent, second frame from the second latent, and so on\n",
    "    images = []\n",
    "    for i, latent in enumerate(latents):\n",
    "        images.append(decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)[0])\n",
    "        \n",
    "    # write images to a gif\n",
    "    images[0].save('../../../content/{}.gif'.format(name), save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "    # write images to a gif with infinite looping\n",
    "    images[0].save('../../../content/{}_infinite.gif'.format(name), save_all=True, append_images=images[1:], duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec400650",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = render_latents(intp_latents)\n",
    "\n",
    "## save images to disk\n",
    "for i, image in enumerate(images):\n",
    "    image.save('../../../content/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a029946",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    render_transformation(intp_latents, 'transformation_render_test_baby')\n",
    "    # render_transformation(intp_latents[0:20], 'transformation_render_test_20_64_3')\n",
    "\n",
    "if 0:\n",
    "    # render_latents(extp_latents, size, 'cube_intp')\n",
    "    images = render_latents(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89587cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0].save('../../../content/{}_{}.gif'.format('cube_debug', '0'), save_all=True, append_images=images[1:], duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cd568",
   "metadata": {},
   "source": [
    "- 17 minutes for size = 128\n",
    "- 12 minutes for size = 64\n",
    "- 50 seconds for size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb717d9",
   "metadata": {},
   "source": [
    "# save latents to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents to file\n",
    "if 0:\n",
    "    torch.save(latents, '../../latents/cube_latents_bbg.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bac3ab",
   "metadata": {},
   "source": [
    "# Automation for folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45809ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cone_bbg.png', 'cone_tall_bbg.png']\n",
      "../../../content/batch_synthetic/cone_bbg.png\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"../../../content/batch_synthetic\"\n",
    "output_folder = \"../../../content/batch_output\"\n",
    "\n",
    "image_files = [file for file in os.listdir(input_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(image_files)\n",
    "image_path = os.path.join(input_folder, image_files[0])\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "714713d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(input_folder, output_folder):\n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = [file for file in os.listdir(input_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Load the image\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        image = load_image(image_path)\n",
    "\n",
    "        batch_size = 1\n",
    "        guidance_scale = 3.0\n",
    "\n",
    "        # computing latent\n",
    "        latent_vector = sample_latents(\n",
    "            batch_size=batch_size,\n",
    "            model=model,\n",
    "            diffusion=diffusion,\n",
    "            guidance_scale=guidance_scale,\n",
    "            model_kwargs=dict(images=[image] * batch_size),\n",
    "            progress=True,\n",
    "            clip_denoised=True,\n",
    "            use_fp16=True,\n",
    "            use_karras=True,\n",
    "            karras_steps=64,\n",
    "            sigma_min=1e-3,\n",
    "            sigma_max=160,\n",
    "            s_churn=0,\n",
    "        )\n",
    "\n",
    "        gif = render_latents(latent_vector)\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        # Save latent vector\n",
    "        latent_vector_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_{index}.npy\")\n",
    "\n",
    "        # Check if a file with same name and index exists and increment index and file name if it does\n",
    "        while os.path.exists(latent_vector_path):\n",
    "            index += 1\n",
    "            print(f\"File {latent_vector_path} already exists, incrementing index to {index}\")\n",
    "            latent_vector_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_{index}.npy\")\n",
    "        torch.save(latent_vector, latent_vector_path)\n",
    "        print(f\"Saved latent vector to {latent_vector_path}\")\n",
    "        del(latent_vector)\n",
    "\n",
    "        # Save GIF\n",
    "        gif_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_{index}.gif\")\n",
    "        gif[0].save(gif_path, save_all=True, append_images=gif[1:], duration=100, loop=0)\n",
    "        print(f\"Saved gif to {gif_path}\")\n",
    "        del(gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf9e9a",
   "metadata": {},
   "source": [
    "- 9m 13.0s\n",
    "- 92m 45.6s (for 48 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16022828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_folder = \"../../../content/batch_sourceimages\"\n",
    "# input_folder = \"../../../content/batch_web\"\n",
    "input_folder = \"../../../content/batch_synthetic\"\n",
    "output_folder = \"../../../content/batch_output\"\n",
    "for i in range(3):\n",
    "    process_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional runs\n",
    "for i in range(20):\n",
    "    process_images(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
