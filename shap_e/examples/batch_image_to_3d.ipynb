{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eed3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f14a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf' for mesh rendering\n",
    "# size = 64 # this is the size of the renders; higher values take longer to render.\n",
    "size = 32 # this is the size of the renders; higher values take longer to render. 16 causes an assertion error.\n",
    "cameras = create_pan_cameras(size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45809ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chair_cushion.png', 'chair_fabric.png']\n",
      "../../../content/batch_pair/chair_cushion.png\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"../../../content/batch_pair\"\n",
    "output_folder = \"../../../content/batch_output\"\n",
    "\n",
    "image_files = [file for file in os.listdir(input_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(image_files)\n",
    "image_path = os.path.join(input_folder, image_files[0])\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d922637",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = load_model('transmitter', device=device) # rendering latents\n",
    "model = load_model('image300M', device=device)\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6f5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_latents(latents):\n",
    "# function for rendering interpolated or extrapolated latents\n",
    "    for i, latent in enumerate(latents):\n",
    "        images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    return images\n",
    "    # images = []\n",
    "    # for latent in latents:\n",
    "    #     images.append(decode_latent_images(xm, latent, cameras, rendering_mode=render_mode))\n",
    "    #     # images[0].save('../../../content/{}_{}.gif'.format(name, i), save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "    # return images\n",
    "\n",
    "def render_transformation(latents, name):\n",
    "# function for rendering the interpolation between two latents as a single gif\n",
    "    # render the first frame from the first latent, second frame from the second latent, and so on\n",
    "    images = []\n",
    "    for i, latent in enumerate(latents):\n",
    "        images.append(decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)[0])\n",
    "        \n",
    "    # write images to a gif\n",
    "    images[0].save('../../../content/{}.gif'.format(name), save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "\n",
    "def process_images(input_folder, output_folder):\n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = [file for file in os.listdir(input_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Load the image\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        image = load_image(image_path)\n",
    "\n",
    "        batch_size = 1\n",
    "        guidance_scale = 3.0\n",
    "\n",
    "        # computing latent\n",
    "        latent_vector = sample_latents(\n",
    "            batch_size=batch_size,\n",
    "            model=model,\n",
    "            diffusion=diffusion,\n",
    "            guidance_scale=guidance_scale,\n",
    "            model_kwargs=dict(images=[image] * batch_size),\n",
    "            progress=True,\n",
    "            clip_denoised=True,\n",
    "            use_fp16=True,\n",
    "            use_karras=True,\n",
    "            karras_steps=64,\n",
    "            sigma_min=1e-3,\n",
    "            sigma_max=160,\n",
    "            s_churn=0,\n",
    "        )\n",
    "\n",
    "        gif = render_latents(latent_vector)\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        # Save latent vector\n",
    "        latent_vector_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_{index}.npy\")\n",
    "\n",
    "        # Check if a file with same name and index exists and increment index and file name if it does\n",
    "        while os.path.exists(latent_vector_path):\n",
    "            index += 1\n",
    "            print(f\"File {latent_vector_path} already exists, incrementing index to {index}\")\n",
    "            latent_vector_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_{index}.npy\")\n",
    "        torch.save(latent_vector, latent_vector_path)\n",
    "        print(f\"Saved latent vector to {latent_vector_path}\")\n",
    "        del(latent_vector)\n",
    "\n",
    "        # Save GIF\n",
    "        gif_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_{index}.gif\")\n",
    "        gif[0].save(gif_path, save_all=True, append_images=gif[1:], duration=100, loop=0)\n",
    "        print(f\"Saved gif to {gif_path}\")\n",
    "        del(gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16022828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403c7dd0d99e42a191811921d3d7c9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved latent vector to ../../../content/batch_output/chair_cushion_0.npy\n",
      "Saved gif to ../../../content/batch_output/chair_cushion_0.gif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefa687a2bbc4fcbab850ff0cee37d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    process_images(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
