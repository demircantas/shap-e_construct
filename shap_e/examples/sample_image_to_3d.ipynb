{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eed3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d922637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7894ba507d40afb53e6d3c26ce9093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.26G [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xm = load_model('transmitter', device=device)\n",
    "model = load_model('image300M', device=device)\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d329d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example_data/cube_tall.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m guidance_scale \u001b[39m=\u001b[39m \u001b[39m3.0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# To get the best result, you should remove the background and show only the object of interest to the model.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# image = load_image(\"example_data/corgi.png\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# image = load_image(\"example_data/cube.png\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m image \u001b[39m=\u001b[39m load_image(\u001b[39m\"\u001b[39;49m\u001b[39mexample_data/cube_tall.png\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m latents \u001b[39m=\u001b[39m sample_latents(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     s_churn\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/demircantas/sm-thesis/shap-e_construct/shap_e/examples/sample_image_to_3d.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m )\n",
      "File \u001b[0;32m~/shap-e/shap_e/util/image_util.py:144\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(image_path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Image\u001b[39m.\u001b[39mImage:\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mwith\u001b[39;00m bf\u001b[39m.\u001b[39;49mBlobFile(image_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m thefile:\n\u001b[1;32m    145\u001b[0m         img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(thefile)\n\u001b[1;32m    146\u001b[0m         img\u001b[39m.\u001b[39mload()\n",
      "File \u001b[0;32m~/anaconda3/envs/shap-e/lib/python3.9/site-packages/blobfile/_ops.py:366\u001b[0m, in \u001b[0;36mBlobFile\u001b[0;34m(path, mode, streaming, buffer_size, cache_dir, file_size, version)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mBlobFile\u001b[39m(\n\u001b[1;32m    337\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    338\u001b[0m     mode: Literal[\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mab\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m     version: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    344\u001b[0m ):\n\u001b[1;32m    345\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m    Open a local or remote file for reading or writing\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m        A file-like object\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mreturn\u001b[39;00m default_context\u001b[39m.\u001b[39;49mBlobFile(\n\u001b[1;32m    367\u001b[0m         path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    368\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    369\u001b[0m         streaming\u001b[39m=\u001b[39;49mstreaming,\n\u001b[1;32m    370\u001b[0m         buffer_size\u001b[39m=\u001b[39;49mbuffer_size,\n\u001b[1;32m    371\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    372\u001b[0m         file_size\u001b[39m=\u001b[39;49mfile_size,\n\u001b[1;32m    373\u001b[0m         version\u001b[39m=\u001b[39;49mversion,\n\u001b[1;32m    374\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/shap-e/lib/python3.9/site-packages/blobfile/_context.py:921\u001b[0m, in \u001b[0;36mContext.BlobFile\u001b[0;34m(self, path, mode, streaming, buffer_size, cache_dir, file_size, version)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m Error(\u001b[39m\"\u001b[39m\u001b[39mCannot specify cache_dir for streaming files\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m _is_local_path(path):\n\u001b[0;32m--> 921\u001b[0m     f \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mFileIO(path, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    923\u001b[0m         f \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBufferedReader(f, buffer_size\u001b[39m=\u001b[39mbuffer_size)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example_data/cube_tall.png'"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "guidance_scale = 3.0\n",
    "\n",
    "# To get the best result, you should remove the background and show only the object of interest to the model.\n",
    "# image = load_image(\"example_data/corgi.png\")\n",
    "# image = load_image(\"example_data/cube.png\")\n",
    "image = load_image(\"../../../content/cube_tall.png\")\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(images=[image] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633da2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d88089c8874de59d32989dd8be70d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhQABAAIcAAOXCVeXCVObBVOXBVuXBVeXBVOXBU+TBVuTBVeTBVOXAV+XAVu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5f711ad01d4af48e8cdc0688bc3948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhQABAAIcAAOXIXeXIXOXIW+XHXeXHXOXHW+bHWeXHWuXHWeTHW+XGXeXGW+…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209505eb10294829b26ac28ad4df4916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhQABAAIcAAObKT+bJUOXJUuXJUeXJUObJT+XJT+XJTuXJTeXIUuXIUeXIUO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acf3938b4f54225bf4b6ed243a22a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhQABAAIcAAOfNAObNAOfMAObMAOXMAObLAOXLAObKAOXKAOXJAOTIAOTGDO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf' for mesh rendering\n",
    "# size = 64 # this is the size of the renders; higher values take longer to render.\n",
    "size = 64 # this is the size of the renders; higher values take longer to render.\n",
    "\n",
    "cameras = create_pan_cameras(size, device)\n",
    "for i, latent in enumerate(latents):\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    display(gif_widget(images))\n",
    "\n",
    "# You can also save the images to a file.\n",
    "images[0].save('cube0.gif', save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "images[1].save('cube1.gif', save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "images[2].save('cube2.gif', save_all=True, append_images=images[1:], duration=100, loop=0)\n",
    "images[3].save('cube3.gif', save_all=True, append_images=images[1:], duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save latents to file\n",
    "torch.save(latents, '../../latents/cube_tall_latents.pt')\n",
    "\n",
    "# load latents from file\n",
    "latents_load = torch.load('../../latents/cube_tall_latents.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
