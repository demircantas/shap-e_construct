{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eed3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d922637",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = load_model('decoder', device=device)\n",
    "model = load_model('text300M', device=device)\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d329d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b80abe196574a68bd1f48212dcb893f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# batch_size = 1\n",
    "guidance_scale = 15.0\n",
    "# prompt = \"a simple cube\"\n",
    "prompts = [\"a cube\", \"a tall cube\"]\n",
    "batch_size = len(prompts)\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    # model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "    model_kwargs=dict(texts=prompts[:batch_size]),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64, # 64 for 256x256, 128 for 512x512\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee8696",
   "metadata": {},
   "source": [
    "# Experiment notes:\n",
    "The cell below renders .gif images of the given latents.\n",
    "## October 20 2023\n",
    "- $\\texttt{size = 128}$ takes over 16 minutes to render two latents.\n",
    "- should I keep using the notebook or create a different design where I start the model up as a service and send client requests to it in a similar way to how we did the Construct() demo for Design X pitch day?\n",
    "- Where and how do I store relevant vectors for useful latents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633da2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4785d9032f7048ffa0175ffcceac5f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhIAAgAIcAALTHuea4AOS4ANa4AJbNqH3SiI++UV/X0FjTdmHAsmDJeW/CcE…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ea3f4d59324a67bdaa1a250556f337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhIAAgAIcAAIJ+i4F+jYF+i4F+ioB+jYB+ioB9jIF9iIF9h4B9iYB9iIB9h3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf'\n",
    "size = 32 # this is the size of the renders; higher values take longer to render. 128 is a good value for presentation.\n",
    "\n",
    "cameras = create_pan_cameras(size, device)\n",
    "for i, latent in enumerate(latents):\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    image_path = f'../../images/experiment-20231020/test{i}.gif'\n",
    "    imageio.mimsave(image_path, images, 'GIF', loop=0)\n",
    "    display(gif_widget(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ded58c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(latents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a089ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents.shape\n",
    "# save torch tensor to file\n",
    "torch.save(latents[0], '../../latents/latent_cube.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dacc97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048576])\n"
     ]
    }
   ],
   "source": [
    "# read latent from file\n",
    "latent_l = torch.load('../../latents/latent_cube.pt')\n",
    "print(latent_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps of latent interpolation\n",
    "n = 8\n",
    "\n",
    "weights = torch.linspace(0, 1, n).unsqueeze(1).to(device)\n",
    "\n",
    "interpolated_latents = torch.lerp(latents[0], latents[1], weights)\n",
    "\n",
    "# Reshape the tensor to have shape (n, 1000)\n",
    "interpolated_latents = interpolated_latents.view(n, -1)\n",
    "\n",
    "size = 32\n",
    "\n",
    "cameras = create_pan_cameras(size, device)\n",
    "for i, latent in enumerate(interpolated_latents):\n",
    "    images_inp = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    image_path_inp = f'/home/demircantas/shap-e/images/test_interpolated{i}.gif'\n",
    "    imageio.mimsave(image_path_inp, images_inp, 'GIF', loop=0)\n",
    "    display(gif_widget(images_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a4dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of saving the latents as meshes.\n",
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "\n",
    "for i, latent in enumerate(latents):\n",
    "    t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "    # with open(f'/home/demircantas/shap-e/meshes/example_mesh_{i}.ply', 'wb') as f:\n",
    "    #     t.write_ply(f)\n",
    "    with open(f'/home/demircantas/shap-e/meshes/example_mesh_{i}.obj', 'w') as f:\n",
    "        t.write_obj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be811c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
